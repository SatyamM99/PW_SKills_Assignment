{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "\n",
        "A parameter is a variable defined in a function's definition that acts as a placeholder for the values (arguments) the function expects to receive when it's called."
      ],
      "metadata": {
        "id": "Lpt4QgqcoIY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is correlation? What does negative correlation mean?\n",
        "\n",
        "Correlation, in the context of data analysis and statistics (often used in Python with libraries like pandas or NumPy), measures the statistical relationship between two or more variables.\n",
        "\n",
        "Negative correlation means that as one variable's value increases, the other variable's value tends to decrease."
      ],
      "metadata": {
        "id": "xM2x368Io3GX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "Machine Learning is a subset of Artificial Intelligence (AI) that enables computers to learn from data and make decisions or predictions without being explicitly programmed for the task. It improves its performance over time as it is exposed to more data.\n",
        "\n",
        "Main Components in Machine Learning (System/Modeling):\n",
        "\n",
        "The core components required to build and run an ML system are:\n",
        "\n",
        "Data: The raw information (examples, images, numbers) used to train the system. Data quality and quantity are crucial.\n",
        "\n",
        "Algorithm: The mathematical procedure or set of rules (e.g., Linear Regression, Neural Network) that learns patterns from the data.\n",
        "\n",
        "Model: The output of the training process. It is the trained algorithm that has learned the patterns and can now be used to make predictions on new, unseen data.\n",
        "\n",
        "Evaluation/Optimization: The process of testing the model's accuracy (evaluation) and adjusting its internal settings (optimization) to minimize errors."
      ],
      "metadata": {
        "id": "U25HxgdzpIEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "The loss value indicates model quality by quantifying the error in its predictions.\n",
        "\n",
        "Lower Loss Value = Better Model: It means the model's predictions are closer to the actual, correct values (the \"ground truth\").\n",
        "\n",
        "Training Goal: The core objective of training a machine learning model is to minimize this loss value.\n",
        "\n",
        "Validation Loss: Monitoring loss on a separate validation set helps detect overfitting (when training loss is very low but validation loss is high, meaning the model can't generalize)."
      ],
      "metadata": {
        "id": "UFgpoUlGpZWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables are numerical values that can take any value within a range (e.g., height, temperature). They are typically measured.\n",
        "\n",
        "Categorical variables are values that represent distinct groups or labels (e.g., color, gender, city). They are typically classified."
      ],
      "metadata": {
        "id": "LdnJA9yApqvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "We handle categorical variables by encoding them, which converts the text-based categories into numerical format that machine learning models can process.\n",
        "\n",
        "One-Hot Encoding- Creates a new binary (0 or 1) column for each category.\n",
        "\n",
        "Ordinal Encoding- Assigns integers that respect the category order (e.g., 1, 2, 3).\n",
        "\n",
        "Label Encoding- Assigns a unique integer to each category, but can imply false order for non-ordinal data.\n",
        "\n",
        "Target/Mean Encoding- Replaces the category with the mean of the target variable for that category.\n",
        "\n",
        "Frequency/Count Encoding- Replaces the category with the number of times it appears in the data."
      ],
      "metadata": {
        "id": "OMVUbpxJp7WV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What do you mean by training and testing a dataset?\n",
        "\n",
        "Training Dataset- The model uses this data to learn patterns and relationships. The training process involves the model constantly adjusting its internal parameters to minimize errors on this set.\n",
        "\n",
        "Testing Dataset- It is used only once at the very end to get an unbiased evaluation of the final model. The model has never seen this data before."
      ],
      "metadata": {
        "id": "xVXbJ5cBq-Pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is sklearn.preprocessing?\n",
        "\n",
        "sklearn.preprocessing is a module within the Python scikit-learn library that provides tools for transforming raw feature vectors into a representation more suitable for machine learning algorithms.\n",
        "\n",
        "It is a crucial step in the data science pipeline because many algorithms perform poorly if the data is not prepared correctly."
      ],
      "metadata": {
        "id": "xTS8FWXArNgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is a Test set?\n",
        "\n",
        "A Test set is a portion of your original dataset that is held back and used only once to evaluate the final performance of a trained machine learning model."
      ],
      "metadata": {
        "id": "H4S3-U_WrWmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "We split the dataset using the train_test_split function from sklearn.model_selection.\n",
        "\n",
        " Approaching a ML Problem is an iterative pipeline:\n",
        "\n",
        "Define Goal: Clearly state what you are trying to predict or classify.\n",
        "\n",
        "Collect/Understand Data: Gather data and analyze it (EDA).\n",
        "\n",
        "Preprocess Data: Clean, handle missing values, scale features, and encode categorical data.\n",
        "\n",
        "Split Data: Separate into training and testing sets.\n",
        "\n",
        "Train Model: Select an algorithm and fit it on the training set.\n",
        "\n",
        "Evaluate & Tune: Assess performance on the testing set and optimize the model.\n",
        "\n",
        "Deploy: Put the final model into production."
      ],
      "metadata": {
        "id": "kCZwK7rureSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "We must perform Exploratory Data Analysis (EDA) before fitting a model because we need to understand the data's structure, quality, and patterns to properly prepare it for the algorithm."
      ],
      "metadata": {
        "id": "-bykkOEKr6jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is correlation?\n",
        "\n",
        "Correlation is a statistical measure that describes the extent and direction to which two or more variables are linearly related; essentially, how they change together.\n",
        "\n",
        "Correlation Coefficient (r): This is a value between -1.0 and +1.0 that quantifies the relationship.\n",
        "\n",
        "Positive Correlation (r>0): Variables move in the same direction. As one increases, the other tends to increase (e.g., hours studied and exam score).\n",
        "\n",
        "Negative Correlation (r<0): Variables move in opposite directions. As one increases, the other tends to decrease (e.g., car age and car price).\n",
        "\n",
        "Zero Correlation (râ‰ˆ0): There is no linear relationship between the variables"
      ],
      "metadata": {
        "id": "ZiM8DFUGsEPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What does negative correlation mean?\n",
        "\n",
        "Negative correlation means that the two variables being compared tend to move in opposite directions. When the value of one variable increases, the value of the other variable tends to decrease."
      ],
      "metadata": {
        "id": "mMEwc-6rsURS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How can you find correlation between variables in Python?\n",
        "\n",
        "Use the .corr() method on a DataFrame to get the Pearson correlation coefficient for all numerical column pairs"
      ],
      "metadata": {
        "id": "9QG7CoopsmGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is causation? Explain difference between correlation and causation with an example\n",
        "\n",
        "Causation is when one event or variable is directly responsible for producing a change in another event or variable. It means that A actually causes B to happen."
      ],
      "metadata": {
        "id": "wdjD3HZ4szhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "An Optimizer is an algorithm or method used to adjust the parameters (weights and biases) of a machine learning model to minimize the loss function. The goal is to find the set of model parameters that results in the lowest error.\n",
        "\n",
        "Stochastic Gradient Descent (SGD)\n",
        "\n",
        "Mini-Batch Gradient Descent (Mini-Batch GD)\n",
        "\n",
        "Advanced Adaptive Optimizers"
      ],
      "metadata": {
        "id": "v6qPftEss50b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is sklearn.linear_model ?\n",
        "\n",
        "sklearn.linear_model is a module within the scikit-learn (sklearn) library in Python that hosts a variety of linear models used for both regression and classification tasks"
      ],
      "metadata": {
        "id": "I85qUJ7qtN_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "The model.fit() method in machine learning libraries like scikit-learn trains a model by applying the learning algorithm to the training data. It is the command that starts the learning process."
      ],
      "metadata": {
        "id": "BSlTF0NotTxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "model.predict() uses a trained machine learning model to generate predictions for new, unseen data. It is the core function for using the model after training."
      ],
      "metadata": {
        "id": "u1CaM5CMtZTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What are continuous and categorical variables?\n",
        "\n",
        "**Continuous variables** are numerical values that can take any value within a given range, including fractions or decimals.\n",
        "\n",
        "Key Idea: They represent measurements and can be infinitely precise.\n",
        "\n",
        "Examples: Height, temperature, time, price, weight\n",
        "\n",
        "\n",
        "**Categorical variables** are values that represent distinct, fixed categories or groups. They can be qualitative (text) or quantitative (numbers representing a category).\n",
        "\n",
        "Key Idea: They represent labels or groups and cannot be logically added or averaged.\n",
        "\n",
        "Types:\n",
        "\n",
        "Nominal: Categories with no inherent order (e.g., color: red, blue, green; marital status: single, married).\n",
        "\n",
        "Ordinal: Categories with a meaningful order or ranking (e.g., educational level: high school, bachelor's, master's; survey rating: low, medium, high)"
      ],
      "metadata": {
        "id": "XiXbD5WutfkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Feature scaling is a data preprocessing technique used to standardize or normalize the range of independent features (variables) in a dataset.\n",
        "\n",
        "It ensures that all features contribute proportionally to the model training process, preventing features with inherently larger values from unfairly dominating the distance calculations or gradient descent updates."
      ],
      "metadata": {
        "id": "n9SNfOtYtxaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. How do we perform scaling in Python?\n",
        "\n",
        "Feature scaling is a data preprocessing technique that standardizes or normalizes the range of independent variables.\n",
        "\n",
        "It helps in Machine Learning by:\n",
        "\n",
        "Speeding up Gradient Descent: It prevents features with larger scales from dominating, leading to faster and more stable convergence.\n",
        "\n",
        "Equalizing Feature Influence: It ensures distance-based models (like k-NN) treat all features equally, preventing features with large magnitudes from unduly influencing the result."
      ],
      "metadata": {
        "id": "Vzodk5iLt6O6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is sklearn.preprocessing?\n",
        "\n",
        "sklearn.preprocessing is a module within the scikit-learn (sklearn) library that provides functions and classes to perform common data preprocessing and cleaning operations on raw feature sets.\n",
        "\n",
        "Its main goal is to prepare data in a format that is more suitable for machine learning algorithms, often by transforming or scaling variables."
      ],
      "metadata": {
        "id": "XBfDJJKGuJzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "The train_test_split Function\n",
        "This function randomly shuffles the data and splits it into four subsets:\n",
        "\n",
        "X_train: Training features (inputs)\n",
        "\n",
        "X_test: Testing features (inputs)\n",
        "\n",
        "y_train: Training target (outputs)\n",
        "\n",
        "y_test: Testing target (outputs)\n",
        "\n"
      ],
      "metadata": {
        "id": "X0O2TlnyuP1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Explain data encoding?\n",
        "\n",
        "Data encoding is the process of converting data from one form (like text categories) into a numerical format that machine learning algorithms can understand and process.\n",
        "\n",
        "Machine learning models, particularly those based on mathematical principles (like linear models or neural networks), require all input features to be numerical. You must encode categorical variables (like 'Color' or 'City') before feeding them to a model."
      ],
      "metadata": {
        "id": "wM_HQADAuiNt"
      }
    }
  ]
}